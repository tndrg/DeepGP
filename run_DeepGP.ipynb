{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title_cell",
   "metadata": {},
   "source": [
    "# DeepGP Genomics Analysis\n",
    "\n",
    "Deep learning-based Genome-wide Predictor, a novel multimodal deep learning framework that incorporates bidirectional state space modules to predict cardiometabolic disease risk using genome-wide variants and demographic data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_desc",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import all necessary libraries for deep learning, genomics data processing, and evaluation metrics. This includes PyTorch Lightning for scalable training, sklearn for metrics, and custom modules for genomics-specific functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Taiyu Zhu\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sklearn import metrics\n",
    "from models import DeepGP\n",
    "from utils import SNPPCACHRDataModule\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from args_generator import args_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_desc",
   "metadata": {},
   "source": [
    "## Configuration and Reproducibility\n",
    "\n",
    "Set random seeds for reproducible experiments and define the model registry and evaluation metrics to track across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "fix_seed = 33\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "base_folder = ''\n",
    "model_dict = {'DeepGP':DeepGP }\n",
    "\n",
    "# Metrics to track\n",
    "fieldnames = ['pheno','accuracy','precision','recall', 'specificity','f1','auc','mcc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_config_desc",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "Initialize experimental configuration parameters including data paths, model settings, and training hyperparameters from the args generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_config_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = args_initial()\n",
    "configs.data_dir = base_folder+'pukb/genes'\n",
    "print('Running experiment for the whole genome')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_desc",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load and preprocess genomic SNP data using a custom DataModule that handles PCA dimensionality reduction, chromosome organization, and train/validation/test splits with proper balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "# SNPPCACHRDataModule: Custom PyTorch Lightning DataModule that:\n",
    "# - Loads SNP data\n",
    "# - Organizes variants by chromosome (CHR-aware processing)\n",
    "snpdata = SNPPCACHRDataModule(configs)\n",
    "\n",
    "# Update model configs with data-specific dimensions\n",
    "configs.enc_len = len(snpdata.genes)                                    # Total number of genetic variants across genome\n",
    "configs.enc_len_chr = [len(snp_chr) for snp_chr in snpdata.genes_chr]  # Number of variants per chromosome (for chr-aware attention)\n",
    "configs.pos = snpdata.pos_chr                                          # Physical genomic positions for positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_desc",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "Initialize the appropriate DeepGP model architecture based on input data type - either SNPs-only for pure genomic analysis or SNPs+covariates for clinical prediction with additional metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model architecture based on data modality\n",
    "if configs.dm == 'snps':\n",
    "    # SNP_Model_mamba: Pure genomic model\n",
    "    # - Takes only SNP genotype data\n",
    "    # - Uses Mamba (state-space model) for long-range genomic dependencies\n",
    "    # - Incorporates chromosome-aware positional encoding\n",
    "    model = model_dict[configs.mn].SNP_Model_mamba(configs)  \n",
    "elif configs.dm == 'snps_covs': \n",
    "    # SNPCOV_Model_mamba: Multi-modal genomic + clinical model\n",
    "    # - Combines SNP data with demographic covariates (age, sex, PCs, etc.)\n",
    "    # - Uses separate encoders for genomic and clinical data\n",
    "    # - Fuses representations for improved phenotype prediction\n",
    "    model = model_dict[configs.mn].SNPCOV_Model_mamba(configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_config_desc",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "Set up experiment tracking, model checkpointing, and early stopping. Configure TensorBoard logging and save the best model based on validation AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_config_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary metric for model selection and early stopping\n",
    "# AUC is preferred for imbalanced genomic datasets over accuracy\n",
    "monitor_acc = 'val_auc'\n",
    "\n",
    "# Setup logging and checkpointing for experiment tracking\n",
    "if configs.save_log:\n",
    "    # Hierarchical logging structure: model_datamode/phenotype/experiment\n",
    "    log_name = f'{configs.mn}_{configs.dm}/{configs.label}'\n",
    "    if len(configs.use_sim)>0:\n",
    "         log_name = log_name+'/sim'  # Separate simulated data experiments\n",
    "    \n",
    "    # TensorBoard logger for training visualization\n",
    "    logger = TensorBoardLogger(save_dir=base_folder+'DeepGP/logs/', name=log_name,version=configs.exp_name)\n",
    "    \n",
    "    # ModelCheckpoint: Save only the best model based on validation AUC\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=monitor_acc,save_top_k=1,mode='max')\n",
    "    \n",
    "    # Callbacks for training control\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=monitor_acc, patience=configs.patience, mode=\"max\"),  # Stop if no improvement\n",
    "        checkpoint_callback  # Save best model\n",
    "    ]\n",
    "    ecb = True\n",
    "else:\n",
    "    # Minimal setup for quick experiments without logging\n",
    "    logger, ecb = False, False\n",
    "    callbacks = [EarlyStopping(monitor=monitor_acc, patience=configs.patience, mode=\"max\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trainer_desc",
   "metadata": {},
   "source": [
    "## Initialize Trainer\n",
    "\n",
    "Configure the PyTorch Lightning trainer with GPU acceleration, callbacks for training control, and validation frequency optimized for large genomic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trainer_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",                    # Use GPU acceleration for large genomic datasets\n",
    "    devices=configs.gpus,                 # Multi-GPU support for distributed training\n",
    "    callbacks=callbacks,                  # Early stopping + model checkpointing\n",
    "    max_epochs=30,                        # Maximum training epochs\n",
    "    val_check_interval=300,               # Validate every 300 training steps (not epochs)\n",
    "    logger=logger,                        # TensorBoard logging\n",
    "    enable_checkpointing=ecb,             # Model checkpointing control\n",
    "    enable_progress_bar=ecb,              # Progress bar display control\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_desc",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "Execute the training loop with automatic validation and early stopping. Load the best checkpoint based on validation AUC and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start training...\")\n",
    "trainer.fit(model, snpdata) \n",
    "\n",
    "# Load best model and test\n",
    "if configs.save_log:\n",
    "    best_model = model.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "else:\n",
    "    best_model = model\n",
    "\n",
    "trainer.test(best_model, snpdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation_desc",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Generate predictions on the test set and calculate comprehensive evaluation metrics including clinical metrics (specificity, sensitivity) and genomics-appropriate measures (AUC, MCC) for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictions from all test batches\n",
    "outputs = trainer.predict(best_model, snpdata)\n",
    "y_pred_proba = np.concatenate([opt[0].numpy() for opt in outputs])  # Predicted probabilities [0,1]\n",
    "y_pred = np.concatenate([opt[1].numpy() for opt in outputs])        # Binary predictions {0,1}\n",
    "y_true = np.concatenate([opt[2].numpy() for opt in outputs])        # True labels {0,1}\n",
    "\n",
    "# Standard classification metrics\n",
    "accuracy = metrics.accuracy_score(y_true, y_pred)                   # Overall correctness\n",
    "precision = metrics.precision_score(y_true, y_pred)                 # PPV: True positives / Predicted positives\n",
    "recall = metrics.recall_score(y_true, y_pred)                       # Sensitivity: True positives / Actual positives\n",
    "\n",
    "# Calculate specificity (True Negative Rate) - important for medical screening\n",
    "# Specificity = TN / (TN + FP) - ability to correctly identify non-cases\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Advanced metrics for imbalanced genomic data\n",
    "f1 = metrics.f1_score(y_true, y_pred)                              # Harmonic mean of precision and recall\n",
    "mcc = metrics.matthews_corrcoef(y_true, y_pred)                    # Matthews Correlation Coefficient (-1 to 1, robust to class imbalance)\n",
    "auc = metrics.roc_auc_score(y_true, y_pred_proba)                  # Area Under ROC Curve (discrimination ability)\n",
    "\n",
    "results_dict = {'pheno': configs.label,'accuracy':accuracy,'precision':precision,\n",
    "                'recall':recall, 'specificity':specificity,'f1':f1,'auc':auc,'mcc':mcc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_desc",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save all experimental results, hyperparameters, and raw predictions in an organized directory structure for reproducibility and downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime('%m-%d_%H-%M')\n",
    "\n",
    "if configs.save_results:\n",
    "    # Create hierarchical results directory structure\n",
    "    # Format: DeepGP/results/{model}_{datamode}/{phenotype}/{experiment_name}/\n",
    "    results_dir = base_folder+f'DeepGP/results/{configs.mn}_{configs.dm}/{configs.label}/{configs.exp_name}'\n",
    "    if len(configs.use_sim)>0:\n",
    "        # Separate directory for simulated data experiments\n",
    "        results_dir = base_folder+f'DeepGP/results/{configs.mn}_{configs.dm}/{configs.label}/sim/{configs.exp_name}'\n",
    "\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    # Save evaluation metrics to CSV for easy analysis\n",
    "    results_csv = f'{results_dir}/results_{now}.csv'\n",
    "    with open(results_csv, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerow(results_dict)\n",
    "    \n",
    "    # Save hyperparameters and configuration as JSON\n",
    "    # Essential for reproducibility and experiment tracking\n",
    "    with open(f'{results_dir}/params_{now}.txt', 'w') as f:\n",
    "        configs.pos = None  # Remove large position arrays to reduce file size\n",
    "        json.dump(configs.__dict__, f, indent=2)\n",
    "    \n",
    "    # Save raw predictions for additional analysis\n",
    "    # Format: (true_labels, predicted_probabilities)\n",
    "    # Useful for ROC curves, calibration plots, error analysis\n",
    "    with open(f'{results_dir}/preds.pkl', 'wb') as f:\n",
    "        pickle.dump((y_true, y_pred_proba), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "display_desc",
   "metadata": {},
   "source": [
    "## Display Results\n",
    "\n",
    "Print all evaluation metrics to console for immediate review of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "if configs.show:\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Specificity: {specificity}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print(f'AUC: {auc}')\n",
    "    print(f'MCC: {mcc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "features_desc",
   "metadata": {},
   "source": [
    "## Key Features\n",
    "\n",
    "- **DeepGP Model**: Uses Mamba (state-space) architecture for modeling long-range genomic dependencies across chromosomes\n",
    "- **Chromosome-aware Processing**: Maintains biological structure with per-chromosome encoding and positional information\n",
    "- **Multi-modal Support**: Handles both SNPs-only and SNPs+covariates (age, sex, PCs) for clinical applications\n",
    "- **Genomics-optimized Metrics**: Focuses on AUC and MCC for imbalanced datasets, includes specificity for medical relevance\n",
    "- **MLOps Ready**: Complete experiment tracking with TensorBoard logging, model checkpointing, and reproducible seeds\n",
    "- **Scalable Architecture**: GPU acceleration and multi-device support for genome-wide datasets\n",
    "- **Clinical Translation**: Saves raw predictions for downstream analysis (ROC curves, risk stratification, calibration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
